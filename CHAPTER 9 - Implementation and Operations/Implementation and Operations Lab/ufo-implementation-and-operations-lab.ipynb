{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation and Operations Lab\n",
    "<font color=\"red\">Notice that this Lab is part C of <a href=\"https://github.com/ipetel/AWS_Certified_ML-acloud.guru/tree/master/CHAPTER%207%20-%20Algorithms/Algorithms%20Lab\">Algorithms Lab</a></font>\n",
    "\n",
    "<u>Use Case</u>\n",
    "<p>Mr. K has given us the go to deploy the optimized Linear Learner model in production! Once this is complete Mr. K's team can use it to investigate any newly reported UFO sighting. \n",
    "Our goal is to deploy the model into production and give Mr. K's team some way to interact with the deployed model. \n",
    "</p>\n",
    "\n",
    "<u>Goal</u>\n",
    "<p>Deploy our Linear Learner model using SageMaker hosting and create a way to interact with the SageMaker endpoint created for the deployed model.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Notebook - Table Of Contents</u>\n",
    "\n",
    "1. [Depoly Model](#d)\n",
    "1. [Hyperparameter Tuning Job](#h)\n",
    "1. [Inference using the Best Training Job](#b)\n",
    "1. [Results](#res)\n",
    "\n",
    "<u>Note</u>\n",
    "1. in most of code cell that I'm using external libraries I'm importing it every time, although I can import all of them once on the start of the notebook, I wanted to show what libraries I'm using on every step.\n",
    "2. there are numerous times that I'm assigning the same variables with the same values on different cells, again just want to to show what variables are used on every step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depoly Model<a id='d'></a>\n",
    "for deploying our trained model we have a couple of options: using SageMaker, ECS, EC2, EMR or on-premise (server or laptop or IoT device).<br>\n",
    "The easiest and the least amount of effort way is using SageMaker (what a surprise!).<br><br>\n",
    "In SageMaker there are two deployments types: <b>SageMaker Batch Transform</b> and <b>SageMaker Hosting Services</b>.<br> the difference between them is usage and cost.<br> \n",
    "- Batch Transform is for offline use and can generate predictions for a whole set of data all at once. \n",
    "- Hosting Services is for online use and will generate one prediction every time input will be sent to it.\n",
    "<br><br>\n",
    "from a cost-wise, a Batch Transform will be billed only for the prediction batch time and on finish will shut down all the used resources, In contrast to Hosting Services is keeping live endpoint on EC2 that is working 24/7.<br><br>\n",
    "\n",
    "so now that we understand this, it looksÂ like we will need to create a live endpoint (SageMaker Hosting Services) for a single prediction at a time.<br><br>\n",
    "<u>great, so what's next? good question!</u><br>\n",
    "in order to create live endpoint we will need the next steps:\n",
    "1. trained model - DONE (from previous labs - <a href=\"https://github.com/ipetel/AWS_Certified_ML-acloud.guru/tree/master/CHAPTER%207%20-%20Algorithms/Algorithms%20Lab\">Algorithms Lab</a> or <a href=\"https://github.com/ipetel/AWS_Certified_ML-acloud.guru/tree/master/CHAPTER%208%20-%20Evaluation%20and%20Optimization/Evaluation%20and%20Optimization%20Lab\">Evaluation and Optimization Lab</a>)\n",
    "1. Create a model - DONE (from previous labs - <a href=\"https://github.com/ipetel/AWS_Certified_ML-acloud.guru/tree/master/CHAPTER%207%20-%20Algorithms/Algorithms%20Lab\">Algorithms Lab</a> or <a href=\"https://github.com/ipetel/AWS_Certified_ML-acloud.guru/tree/master/CHAPTER%208%20-%20Evaluation%20and%20Optimization/Evaluation%20and%20Optimization%20Lab\">Evaluation and Optimization Lab</a>)\n",
    "1. Create Endpoint configuration\n",
    "1. Create a Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Endpoint configuration + Create a Endpoint\n",
    "get the best model Training Job Name (from <a href=\"https://github.com/ipetel/AWS_Certified_ML-acloud.guru/tree/master/CHAPTER%208%20-%20Evaluation%20and%20Optimization/Evaluation%20and%20Optimization%20Lab\">Evaluation and Optimization Lab</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "hyperparameter_tuning_job_name='ll-multiclass-HyperparamTuning-1'\n",
    "tuning_job_result=boto3.client('sagemaker').describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=hyperparameter_tuning_job_name)\n",
    "best_training_job_name = tuning_job_result['BestTrainingJob']['TrainingJobName']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a model object from existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "# get IAM role\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "\n",
    "# Configure training job, establish SagMaker session\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# from \"Evaluation and Optimization Lab\" under \"Inference using the Best Training Job\"\n",
    "model_name='best-training-job-LinearLearner-1'\n",
    "bucket_name = 'allcloud-idan-aws-certified-ml-2019'\n",
    "\n",
    "# get ECR container\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(boto3.Session().region_name, 'linear-learner','1')\n",
    "\n",
    "#for more info about \"Model\" go to :https://sagemaker.readthedocs.io/en/stable/model.html\n",
    "best_training_job_model=sagemaker.model.Model(model_data='s3://{}/'.format(bucket_name)+'EvaluationAndOptimizationLab - 2019/output/'+best_training_job_name+'/output/model.tar.gz',\n",
    "                                              role=role,\n",
    "                                              image=container,\n",
    "                                              name=model_name,\n",
    "                                              sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Endpoint configuration + Create a Endpoint<br>\n",
    "(Deploy the Model to Amazon SageMaker Hosting Services using Amazon SageMaker Python SDK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: best-training-job-LinearLearner-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "#https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-deploy-model.html#ex1-deploy-model-sdk\n",
    "\n",
    "best_training_job_model.deploy(initial_instance_count=1,\n",
    "                               instance_type='ml.m4.xlarge',\n",
    "                               endpoint_name='linear-learner-endpoint-1',\n",
    "                               wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create RealTimePredictor object to run prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import json_serializer, csv_serializer, json_deserializer\n",
    "from sagemaker.content_types import CONTENT_TYPE_CSV, CONTENT_TYPE_JSON\n",
    "\n",
    "model_predictor = sagemaker.predictor.RealTimePredictor(endpoint='linear-learner-endpoint-1',\n",
    "                                                        sagemaker_session=sess,\n",
    "                                                        serializer=csv_serializer,\n",
    "                                                        deserializer=json_deserializer,\n",
    "                                                        content_type=CONTENT_TYPE_CSV,\n",
    "                                                        accept=CONTENT_TYPE_JSON)\n",
    "\n",
    "#for more info about 'RealTimePredictor' and 'predict' go to: https://sagemaker.readthedocs.io/en/stable/predictors.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now that we have RealTimePredictor object we can run real time predictor<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's create a fake record to check the endpoint\n",
    "#the order of the new_record values fit the order of the next columns: \n",
    "#[duration,latitude,longitude,researchOutcome,hasPhysicalEvidence,hadContact,shape_box,shape_circle,shape_disk,shape_light,shape_oval,shape_pyramid,shape_sphere,shape_square,shape_triangle]\n",
    "new_record='50,30.30,-96.96,1,1,0,0,0,0,0,0,0,1,0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'researchOutcome' prediction for the 'new_record' is: unexplained\n"
     ]
    }
   ],
   "source": [
    "prediction=model_predictor.predict(data=new_record)\n",
    "predicted_label=int(prediction['predictions'][0]['predicted_label'])\n",
    "\n",
    "\n",
    "researchOutcome_dict={'unexplained': 0, 'explained': 1, 'probable': 2}\n",
    "predicted_researchOutcome=list(researchOutcome_dict.keys())[list(researchOutcome_dict.values()).index(predicted_label)]\n",
    "print(\"'researchOutcome' prediction for the 'new_record' is: {}\".format(predicted_researchOutcome))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice om finish to delete the live endpoint - it's cost you money !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
